{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780316fd-93ba-4424-95d5-199c3e673513",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0574394-2773-419e-b402-93d99e9dc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce474282-bfe5-4cde-816d-8479404f1d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b00d01ab-91bf-493f-be01-dac93f19fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatflare.prompt.base import PromptTemplate\n",
    "from chatflare.core.llm_wrapper import BaseChain\n",
    "from chatflare.model.openai import ChatOpenAI\n",
    "from chatflare.model.llama_bedrock import LlamaBedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "668b0ba9-a967-43b8-a83f-84a6f5791434",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LlamaBedrock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7652fe36-f770-4478-bb90-105c2ef2adda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"../bedrock.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a95b687-b96e-423c-b578-24a210438305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/qiurui/Desktop/research/2023 further/perspecto-cards/server/ChatFlare\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6d18ee9-dcfe-4eab-a1fa-1ef2164c981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE              \u001b[1m\u001b[36mchatflare.egg-info\u001b[m\u001b[m   setup.py\n",
      "README.md            \u001b[1m\u001b[36mdocs\u001b[m\u001b[m                 \u001b[1m\u001b[36mtest_history_control\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36massets\u001b[m\u001b[m               \u001b[1m\u001b[36mnotebooks\u001b[m\u001b[m            \u001b[1m\u001b[36mtests\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mchatflare\u001b[m\u001b[m            requirements-dev.txt\n",
      "\u001b[1m\u001b[36mchatflare-venv\u001b[m\u001b[m       requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "351a70e4-1b4e-4e0b-b1f6-2236d6f7a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from PyPDF2 import PdfReader\n",
    "pdf_path = \"./tests/example_docs/sample_med2.pdf\"\n",
    "with open(pdf_path, 'rb') as file:\n",
    "    reader = PdfReader(file)\n",
    "    num_pages = len(reader.pages)\n",
    "    text = \"\"\n",
    "    inside_section = False\n",
    "    pages = []\n",
    "    for i in range(num_pages):\n",
    "        page = reader.pages[i]\n",
    "        page_text = page.extract_text()\n",
    "        pages.append(page_text)\n",
    "\n",
    "sumLength = 0\n",
    "for page in pages: \n",
    "    sumLength += len(page)\n",
    "\n",
    "summed_doc = \"\\n\".join(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64a27093-3d5d-4118-8ee8-2c4d342d62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_PROMPT_PREFIX = \"\"\"You are an research agent designed to help human perform an literature review tasks from a set of documents.\n",
    "You are give a task to review information of the given research question: {{query}}.\n",
    "You are given a paper to read, and you need to summarize the information relevant to the given topic and also the overall information of the document that you feel important or interesting or worth to dive in. \n",
    "{{paper_already_read}}\n",
    "{{findings_so_far}}\n",
    "The paper you need to read is below and is wrapped between a pair of triple backticks:  \n",
    "```\n",
    "{{paper_to_read}}\n",
    "```\n",
    "Be careful that the paper you are assigned might not relevant to the research question: {{query}}. But if it is relevant, you also are required to generate a overall thought to reflect your understanding of the given topic `{{query}}`so far, based on this paper, papers you have already read and your findings. \n",
    "Be careful about the conflict findings from this paper and the papers you have read (if you have), do not judge which one is more reasonable based on our understanding, just write it to your thought and wait for further exploration!\n",
    "{{inspiration_conversation_history}}\n",
    "\n",
    "{RESPONSE_FORMAT}\n",
    "\"\"\"\n",
    "\n",
    "READ_RESPONSE_FORMAT = \"\"\"\n",
    "When responding use a markdown code snippet with a JSON object formatted in the \\\n",
    "following schema:\n",
    "```json\n",
    "{{  \n",
    "    \"findings_of_the_paper\": str, //the information in the paper that directly related to the given research question `{{query}}`, return `not included` if it does not contain the information that can directly relate to the research question\n",
    "    \"related_to_query\": bool, //whether the paper is directly related to the given research question `{{query}}`, \n",
    "    \"reason_of_exclusion\": str, //if your answer was `false` in \"related_to_query\", you need to provide the reason why you think it is not related to the research question `{{query}}\n",
    "    \"summary_of_the_paper\": str, //summary of the paper given to you, include the information that you feel important and worth further exploration\n",
    "    \"thought\": str, //your overall understanding of question `{{query}}` so far, not just from this paper but also your previous findings. Do not include irrelevant information here. Pay attention to the length of your thought, it should be no longer than 500 words.    \n",
    "}}\n",
    "```\n",
    "Return only the makrdown and Nothing Else!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee899d13-6aff-4b6a-aac4-920995cacca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_PROMPT_PREFIX = \"\"\"You are an research agent designed to help human perform an literature review tasks from a set of documents.\n",
    "You are give a task to review information of the given research question: {{query}}.\n",
    "You are given a paper to read, and you need to summarize the information relevant to the given topic and also the overall information of the document that you feel important or interesting or worth to dive in. \n",
    "{{paper_already_read}}\n",
    "{{findings_so_far}}\n",
    "The paper you need to read is below and is wrapped between a pair of triple backticks:  \n",
    "```\n",
    "{{paper_to_read}}\n",
    "```\n",
    "Be careful that the paper you are assigned might not relevant to the research question: {{query}}. But if it is relevant, you also are required to generate a overall thought to reflect your understanding of the given topic `{{query}}`so far, based on this paper, papers you have already read and your findings. \n",
    "Be careful about the conflict findings from this paper and the papers you have read (if you have), do not judge which one is more reasonable based on our understanding, just write it to your thought and wait for further exploration!\n",
    "{{inspiration_conversation_history}}\n",
    "\n",
    "{RESPONSE_FORMAT}\n",
    "\"\"\"\n",
    "\n",
    "READ_RESPONSE_FORMAT = \"\"\"\n",
    "When responding use a markdown code snippet with a JSON object formatted in the \\\n",
    "following schema:\n",
    "```json\n",
    "{{  \n",
    "    \"findings_of_the_paper\": str, //the information in the paper that directly related to the given research question `{{query}}`, return `not included` if it does not contain the information that can directly relate to the research question\n",
    "}}\n",
    "```\n",
    "Return only the makrdown and Nothing Else!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c363074-c1b8-4b84-8284-76152c61ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = READ_PROMPT_PREFIX.format(RESPONSE_FORMAT=READ_RESPONSE_FORMAT)\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5409b527-f4bd-4587-9de3-60b0e7e729b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['query',\n",
       " 'paper_already_read',\n",
       " 'findings_so_far',\n",
       " 'paper_to_read',\n",
       " 'query',\n",
       " 'query',\n",
       " 'inspiration_conversation_history']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bfd2714-287c-4934-9d1b-e8dc13073a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = BaseChain(model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1151b7cc-8a8b-45e6-8970-579fae0c6fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what's the summary of this paper\"\n",
    "paper_already_read = \"\"\n",
    "findings_so_far = \"\"\n",
    "paper_to_read = summed_doc[:200]\n",
    "inspiration_conversation_history = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92c6f2fd-f0c3-4d1f-85b7-8954efe13aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.turn_on_json_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72d52005-0c3a-4f2d-a407-2625d7f91aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = chain.predict(query=query, paper_already_read=paper_already_read, findings_so_far=findings_so_far, paper_to_read=paper_to_read, inspiration_conversation_history=inspiration_conversation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b661c75-08f6-46b3-b5cf-55f450d6456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d561552f-fdad-411e-9a14-54ce46d756f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'findings_of_the_paper': 'not included'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "109d3776-d4c0-45e6-bd2c-705f723a1751",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2 = await chain.apredict(query=query, paper_already_read=paper_already_read, findings_so_far=findings_so_far, paper_to_read=paper_to_read, inspiration_conversation_history=inspiration_conversation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f0b29d0-c914-420e-9f5d-9a3856465a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'findings_of_the_paper': 'The paper investigates the administration time-dependent antihypertensive efficacy of telmisartan in patients with essential hypertension. It compares the efficacy of morning versus evening administration of telmisartan, with 215 patients randomly assigned to receive telmisartan (80 mg/d) as a monotherapy either on awakening or at bedtime. The study aims to determine if the administration time-dependent efficacy is a class-related feature of all angiotensin receptor blockers or specific to valsartan, given that telmisartan has a distinct terminal half-life compared to other angiotensin receptor blockers.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(res_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8828b4f7-e938-4684-9264-6e7597730a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{  \\n    \"findings_of_the_paper\": \"The paper investigates the administration time-dependent antihypertensive efficacy of telmisartan in patients with essential hypertension. It compares the efficacy of morning versus evening administration of telmisartan, with 215 patients randomly assigned to receive telmisartan (80 mg/d) as a monotherapy either on awakening or at bedtime. The study aims to determine if the administration time-dependent efficacy is a class-related feature of all angiotensin receptor blockers or specific to valsartan, given that telmisartan has a distinct terminal half-life compared to other angiotensin receptor blockers.\"\\n}\\n         '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda4bc9e-7861-4802-a053-1e0cb3aef328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insight-agent-prod",
   "language": "python",
   "name": "insight-agent-venc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
